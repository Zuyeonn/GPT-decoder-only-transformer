{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db59f1-6ae5-428a-9b65-a34b1e7b5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 모델 설정\n",
    "model_config = 'PPG_PT'  # 'PPG_PT' 또는 'ECG_PT' 선택\n",
    "\n",
    "block_size = 500  # 컨텍스트 길이\n",
    "n_embd = 64\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "dropout = 0.2\n",
    "model_path_ppg = \"PPGPT_500k_iters.pth\"\n",
    "model_path_ecg = \"ECGPT_560k_iters.pth\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if model_config == 'PPG_PT':\n",
    "    vocab_size = 102  # PPG 모델\n",
    "    model_path = model_path_ppg\n",
    "elif model_config == 'ECG_PT':\n",
    "    vocab_size = 101  # ECG 모델\n",
    "    model_path = model_path_ecg\n",
    "\n",
    "\n",
    "# 2. 데이터 전처리 함수 (정규화 및 토큰화)\n",
    "def tokenize_biosignal(data):\n",
    "    if isinstance(data, list): \n",
    "        data = np.array(data)\n",
    "    if len(data.shape) == 1:\n",
    "        data = data.reshape(1, -1)\n",
    "\n",
    "    # 정규화 (0~1 범위)\n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    data_scaled = (data - data_min) / (data_max - data_min)\n",
    "\n",
    "    # 0~100 정수 변환\n",
    "    data_scaled *= 100\n",
    "    data_rounded = np.round(data_scaled).astype(int)\n",
    "\n",
    "    return data_rounded\n",
    "\n",
    "\n",
    "# 3. HeartGPT 모델 클래스 정의\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones((block_size, block_size))))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k, q, v = self.key(x), self.query(x), self.value(x)\n",
    "        wei = (q @ k.transpose(-2, -1)) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Heart_GPT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "# 4. 모델 로드 및 초기화\n",
    "model = Heart_GPT_Model()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# 5. 데이터 로드 및 전처리\n",
    "file_path = \"ppg_data2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# 데이터 변환\n",
    "ppg_data = df[\"ppg_data\"].values.reshape(1, -1)\n",
    "tokenized_ppg = tokenize_biosignal(ppg_data)\n",
    "example_context_tensor = torch.tensor(tokenized_ppg, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "# 6. 모델을 사용하여 새로운 데이터 생성\n",
    "generated_tokens = model.generate(example_context_tensor, max_new_tokens=500)[0].tolist()\n",
    "\n",
    "\n",
    "# 7. 생성된 데이터 저장\n",
    "output_df = pd.DataFrame(generated_tokens, columns=[\"generated_data\"])\n",
    "output_path = \"GPT_model_output.csv\"\n",
    "output_df.to_csv(output_path, index=False)\n",
    "print(f\"생성된 데이터 저장 완료: {output_path}\")\n",
    "\n",
    "sampling_rate = 50\n",
    "original_time = np.arange(len(tokenized_ppg[0])) / sampling_rate\n",
    "generated_time = np.arange(len(tokenized_ppg[0]), len(tokenized_ppg[0]) + len(generated_tokens)) / sampling_rate\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(original_time, tokenized_ppg[0], label=\"Context\", color=\"black\", linewidth=1.2)\n",
    "plt.plot(generated_time, generated_tokens, label=\"PPGPT Prediction\", color=\"red\", linewidth=1.2)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Tokenized Value\")\n",
    "plt.title(\"PPG-PT Prediction\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde2b10-62b0-4045-8f21-1bf6e5c7c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
